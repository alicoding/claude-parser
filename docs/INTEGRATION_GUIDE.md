# Claude Parser SDK - Integration Guide

## üéØ BCM Assessment Solution

This guide shows how Claude Parser SDK solves the **BUY vs BUILD** decision for transcript monitoring/parsing components.

---

## üìä BCM Assessment: BUY Decision Justified

### Current Problem (300 Lines to Replace)

Your project currently implements:

```python
# CURRENT BUILD (What Claude Parser SDK replaces):
- File monitoring: watchfiles (KEEP THIS ‚úÖ)
- JSON parsing: Manual json.loads() + try/catch (REPLACE ‚ùå)
- Format detection: Custom logic (REPLACE ‚ùå)  
- Content extraction: Manual .get() calls (REPLACE ‚ùå)
- Session ID extraction: File path parsing (REPLACE ‚ùå)
- Deduplication: Custom Set tracking (REPLACE ‚ùå)

# TOTAL: ~250 lines of parsing logic (keeping ~50 lines of file watching)
```

### Claude Parser SDK Solution (15 Lines)

```python
from claude_parser import load

def monitor_transcript(jsonl_file):
    """Replace entire transcript monitoring component."""
    
    # 1. Load conversation (replaces manual JSON parsing + 80 lines)
    conv = load(jsonl_file)
    
    # 2. Extract events (replaces manual field access + format detection)
    events = []
    for tool in conv.tools:  # Handles both ToolUse and ToolResult
        events.append({
            'type': 'tool_event',
            'tool': tool.tool_name,
            'content': tool.text_content,
            'session': conv.session_id,
            'timestamp': tool.timestamp
        })
    
    return events  # Bridge to your Redis system

# Integration point (keep your platform integration)
def bridge_to_communication_pack(events):
    """Bridge library events to your platform"""
    for event in events:
        QueuePattern.push(f'events:{event["type"]}', event)
```

---

## ‚úÖ BUY Decision Matrix Results

| Capability | Your Implementation | Claude Parser SDK | Decision |
|------------|-------------------|------------------|----------|
| **File Watching** | watchfiles | ‚ùå **NOT PROVIDED** | **Keep yours** |
| **JSON Parsing** | Manual 80 lines ‚ùå | ‚úÖ orjson (10x faster) | **BUY** |
| **Format Detection** | Custom logic | ‚úÖ Auto-detects + validation | **BUY** |
| **Content Extraction** | Manual field access | ‚úÖ Polymorphic properties | **BUY** |
| **Session Context** | File path parsing | ‚úÖ Built-in session_id | **BUY** |
| **Error Handling** | Custom try/catch | ‚úÖ Graceful error recovery | **BUY** |

### Decision: **STRONG BUY** ‚úÖ

- **Eliminates**: 300 lines ‚Üí 15 lines (95% reduction)
- **Better**: Uses battle-tested libraries (orjson, pydantic v2)
- **Faster**: 10x JSON parsing performance 
- **Safer**: Built-in error handling and validation
- **Simpler**: Zero configuration required

---

## üöÄ Implementation Strategy

### Phase 1: Replace Parser Component Only

**Keep Your Current Architecture:**
```
[File Watcher] ‚Üí [Claude Parser SDK] ‚Üí [Redis Bridge] ‚Üí [Event Handlers]
     YOURS             NEW                YOURS           YOURS
   (watchfiles)    (PARSING ONLY)
```

**Important**: Claude Parser SDK (Phase 1) only handles **parsing JSONL files**. You keep your existing file watching solution.

**Coming in Phase 2**: Real-time file watching + improved Claude Code hooks will be included.

**Integration Code:**
```python
# your_project/transcript_monitor.py
from claude_parser import load
from your_platform import QueuePattern

class TranscriptMonitor:
    def __init__(self):
        # KEEP: Your existing file watching setup (we don't provide this)
        self.watcher = your_existing_file_watcher  # watchfiles, etc.
    
    def process_transcript(self, jsonl_file):
        """Replace your 300-line parsing logic with this."""
        
        # NEW: Use Claude Parser SDK (replaces all custom parsing)
        try:
            conv = load(jsonl_file)
        except Exception as e:
            self.log_error(f"Failed to parse {jsonl_file}: {e}")
            return
        
        # NEW: Extract structured data (replaces manual field access)
        events = self._extract_events(conv)
        
        # KEEP: Your platform integration
        self._bridge_to_platform(events)
    
    def _extract_events(self, conv):
        """Extract events using Claude Parser SDK."""
        events = []
        
        # Tool events
        for tool in conv.tools:
            events.append({
                'type': 'tool_event',
                'tool': tool.tool_name,
                'parameters': getattr(tool, 'parameters', {}),
                'result': tool.text_content,
                'session': conv.session_id,
                'timestamp': tool.timestamp
            })
        
        # User events  
        for msg in conv.user_messages:
            events.append({
                'type': 'user_message',
                'content': msg.text_content,
                'session': conv.session_id,
                'timestamp': msg.timestamp
            })
        
        # Assistant events
        for msg in conv.assistant_messages:
            events.append({
                'type': 'assistant_message', 
                'content': msg.text_content,
                'session': conv.session_id,
                'timestamp': msg.timestamp
            })
        
        return events
    
    def _bridge_to_platform(self, events):
        """KEEP: Your existing Redis bridge logic."""
        for event in events:
            QueuePattern.push(f'events:{event["type"]}', event)
```

### Phase 2: Enhanced Features (Optional)

Once Phase 1 is working, you can leverage additional SDK features:

```python
# Advanced features you get for free
def enhanced_analysis(jsonl_file):
    conv = load(jsonl_file)
    
    # Search capabilities
    error_messages = conv.with_errors()
    python_mentions = conv.search("python", case_sensitive=False)
    
    # Context extraction
    recent_context = conv.before_summary(limit=10)
    
    # Metadata
    working_dir = conv.current_dir
    git_branch = conv.git_branch
    
    return {
        'errors': len(error_messages),
        'python_usage': len(python_mentions),
        'context_messages': len(recent_context),
        'environment': {
            'cwd': working_dir,
            'branch': git_branch
        }
    }
```

---

## üîß Integration Checklist

### Prerequisites
```bash
# Add to your project
pip install claude-parser-sdk  # When published
# OR for now:
git clone /path/to/claude-parser
pip install ./claude-parser
```

### Integration Steps

#### 1. **Backup Current Implementation**
```bash
# Keep your current code as backup
cp transcript_parser.py transcript_parser.py.backup
```

#### 2. **Replace Parser Logic**
```python
# OLD (300 lines):
def parse_transcript(file_path):
    with open(file_path, 'r') as f:
        for line in f:
            try:
                data = json.loads(line)
                # 295 more lines of custom parsing...
            except:
                # Custom error handling...

# NEW (15 lines):
def parse_transcript(file_path):
    from claude_parser import load
    conv = load(file_path)
    return conv  # All parsing done!
```

#### 3. **Update Event Extraction**
```python
# OLD (manual field access):
if 'toolUse' in data:
    tool_name = data['toolUse'].get('name', '')
    # More manual extraction...

# NEW (polymorphic properties):
for tool in conv.tools:
    tool_name = tool.tool_name  # Works for all tool types
    content = tool.text_content  # Consistent interface
```

#### 4. **Test Integration**
```python
def test_integration():
    # Test with real file
    conv = load("path/to/your/transcript.jsonl")
    
    print(f"‚úÖ Loaded {len(conv)} messages")
    print(f"‚úÖ Found {len(conv.tools)} tools")
    print(f"‚úÖ Session: {conv.session_id}")
    
    # Test your bridge
    events = extract_events(conv)
    bridge_to_platform(events)
    print(f"‚úÖ Bridged {len(events)} events")
```

#### 5. **Gradual Rollout**
```python
# Feature flag for gradual migration
USE_CLAUDE_PARSER = os.getenv('USE_CLAUDE_PARSER', 'false').lower() == 'true'

def process_transcript(file_path):
    if USE_CLAUDE_PARSER:
        return new_parser_logic(file_path)  # Claude Parser SDK
    else:
        return old_parser_logic(file_path)   # Your 300 lines
```

---

## üìà Expected Benefits

### Immediate Benefits
- **-235 lines of code** (250 parsing lines ‚Üí 15 lines)
- **10x faster JSON parsing** (orjson vs manual)
- **Built-in error recovery** (vs custom try/catch)
- **Zero configuration** (vs setup complexity)
- **Keep your file watching** (we only handle parsing)

### Long-term Benefits  
- **Battle-tested libraries** (orjson, pydantic v2)
- **Type safety** (pydantic models vs dict access)
- **Future-proof** (library handles format changes)
- **Extensible** (5% API for advanced features)

### Risk Mitigation
- **Gradual migration** (feature flag approach)
- **Fallback option** (keep old code as backup)
- **Comprehensive tests** (92 test cases included)
- **Real-world validated** (tested with actual Claude exports)

---

## üîç Performance Comparison

### Before (Your 300 Lines)
```python
# Manual JSON parsing
with open(file_path, 'r') as f:
    for line in f:
        data = json.loads(line)  # Python's json module
        # Manual field extraction
        # Custom error handling
        # Custom deduplication
```

### After (Claude Parser SDK)
```python
# Optimized parsing with orjson + pydantic
conv = load(file_path)  # 10x faster JSON parsing
# Automatic field extraction via properties
# Built-in error handling  
# Built-in deduplication
```

**Benchmarks:**
- **Parsing**: 10x faster (orjson vs json)
- **Memory**: 4x file size (vs unpredictable custom code)
- **Error Rate**: Near-zero (vs custom error handling)

---

## üö® Migration Risks & Mitigations

### Risk 1: Breaking Changes
**Mitigation**: Feature flag + gradual rollout
```python
USE_CLAUDE_PARSER = os.getenv('USE_CLAUDE_PARSER', 'false')
```

### Risk 2: Different Data Structure
**Mitigation**: Bridge adapter pattern
```python
def adapt_old_to_new(claude_parser_event):
    """Adapt new format to your existing event structure."""
    return {
        'old_field_name': claude_parser_event['new_field_name'],
        # Map other fields...
    }
```

### Risk 3: Performance Regression
**Mitigation**: Benchmarking + monitoring
```python
import time
start = time.time()
conv = load(file_path)
parse_time = time.time() - start
# Log metrics, compare with old implementation
```

### Risk 4: Unknown Edge Cases  
**Mitigation**: Comprehensive testing with your real data
```python
# Test with all your actual transcript files
test_files = glob.glob("path/to/your/transcripts/*.jsonl")
for file_path in test_files:
    try:
        conv = load(file_path)
        assert len(conv) > 0, f"Empty conversation: {file_path}"
    except Exception as e:
        print(f"Failed to parse {file_path}: {e}")
```

---

## üéØ Success Criteria

### Technical Success
- [ ] All transcript files parse successfully
- [ ] Event extraction works correctly  
- [ ] Platform integration functions properly
- [ ] Performance equals or exceeds current implementation
- [ ] No data loss during parsing

### Business Success
- [ ] **94% parsing code reduction** (250 ‚Üí 15 lines)
- [ ] **Reduced maintenance burden** (no custom parsing logic)
- [ ] **Improved reliability** (battle-tested libraries)
- [ ] **Future extensibility** (5% API for advanced features)

---

## üÜò Support & Troubleshooting

### Common Issues

#### Issue: FileNotFoundError
```python
try:
    conv = load("transcript.jsonl")
except FileNotFoundError:
    print("‚ùå File not found - check path")
```

#### Issue: ValueError (malformed JSONL)
```python
try:
    conv = load("transcript.jsonl", strict=True)
except ValueError as e:
    print(f"‚ùå Format error: {e}")
    # Fallback to non-strict mode
    conv = load("transcript.jsonl", strict=False)
```

#### Issue: Empty tool_uses
```python
conv = load("transcript.jsonl")
if not conv.tools:
    print("‚ÑπÔ∏è  No tools found - check message types")
    print(f"Message types: {[msg.type for msg in conv.messages[:5]]}")
```

### Debug Mode
```python
# Enable debug logging
import logging
logging.basicConfig(level=logging.DEBUG)

from claude_parser import load
conv = load("transcript.jsonl")  # Will show detailed parsing info
```

### Getting Help
- **API Reference**: `docs/API_REFERENCE.md`
- **GitHub Issues**: Create issue with sample JSONL file
- **Integration Support**: Include your bridge code in issue

---

## üìã Migration Timeline

### Week 1: Preparation
- [ ] Install Claude Parser SDK
- [ ] Run compatibility tests with your JSONL files
- [ ] Backup current implementation

### Week 2: Implementation  
- [ ] Replace parser logic (15 lines)
- [ ] Update event extraction
- [ ] Test bridge integration

### Week 3: Testing
- [ ] Unit tests with real data
- [ ] Performance benchmarking
- [ ] Error handling validation

### Week 4: Deployment
- [ ] Feature flag deployment
- [ ] Monitor metrics
- [ ] Gradual rollout (10% ‚Üí 50% ‚Üí 100%)

**Total Migration Time: 4 weeks for 94% parsing code reduction**

---

## üöÄ Phase 2 Roadmap (Coming Soon)

### Real-time File Watching
Replace your watchfiles implementation with our integrated solution:

```python
# Future Phase 2 API
from claude_parser import watch

def on_new_messages(conv, new_messages):
    # Your existing bridge logic
    events = extract_events_from_messages(new_messages)
    bridge_to_platform(events)

# One-liner replaces your entire file watching setup
watch("transcript.jsonl", on_new_messages)
```

### Hook Integration Helpers  
Simplify working with official Anthropic Claude Code hooks:

```python
# Current manual approach (verbose)
import json
import sys

try:
    input_data = json.load(sys.stdin)
except json.JSONDecodeError as e:
    print(f"Error: Invalid JSON input: {e}", file=sys.stderr)
    sys.exit(1)

tool_name = input_data.get("tool_name", "")
if tool_name == "Write":
    print("Blocked", file=sys.stderr)
    sys.exit(2)
else:
    sys.exit(0)

# Future Phase 2 helpers (simple)
from claude_parser.hooks import parse_hook_input, exit_success, exit_block

data = parse_hook_input()  # Type-safe parsing
if data.tool_name == "Write":
    exit_block("Blocked")
exit_success()
```

**Benefits:**
- ‚úÖ Type-safe hook input parsing
- ‚úÖ Built-in error handling
- ‚úÖ Helper functions for common patterns  
- ‚úÖ Works with official Anthropic hooks (not a replacement)

---

## üåü Conclusion

Claude Parser SDK provides a **clear BUY decision** for your transcript monitoring component:

‚úÖ **Eliminates 300 lines** of custom parsing logic  
‚úÖ **10x performance improvement** with orjson  
‚úÖ **Battle-tested reliability** with 92 test cases  
‚úÖ **Zero configuration** required  
‚úÖ **Future-proof** with extensible 5% API  

**Integration is simple**: Replace your custom parsing with `conv = load(file_path)` and bridge the events to your existing platform.

Your platform integration (Redis, event handlers) **remains unchanged** - you only replace the problematic parsing component with a robust, tested library.

**Start your migration today!** üöÄ